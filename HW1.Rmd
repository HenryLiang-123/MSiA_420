---
title: "MSiA_420_HW1"
output: pdf_document
date: "2023-01-16"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(boot)
```

## Question 1

See attached

## Question 2

### a

```{r q2a, echo=FALSE}
########### QUESTION 2 begins here ################### 
dat <- read_csv("HW1_data.csv")
dat <- dat %>%
  select(y,x)
m1 <- lm(y~x, data = dat)
summary(m1)
```

As seen above, the coefficients $\hat{\beta_0}$ and $\hat{\beta_1}$ are 5.4207 and 0.4896, respectively. Thus, the initial guesses of the form $\hat{\gamma_0} = \frac{1}{\hat{\beta_0}} = \frac{1}{5.4207} = 0.1845$, and $\hat{\gamma_1} = \frac{\hat{\beta_1}}{\hat{\beta_0}} = \frac{0.48964}{5.4207} = 0.0903$ 

### b

```{r q2b, echo=FALSE}
est <- c(0.1845, 0.0903)
x_i <- dat$x
y_i <- dat$y
fn <- function(p) {
    yhat <- (p[1] * x_i) / (p[2] + x_i)
    sum((y_i-yhat)^2)
} 
out_nlm <- nlm(fn, p = est,hessian=TRUE)
theta_nlm <- out_nlm$estimate  #parameter estimates
theta_nlm
out_nls <- nls(y~((p1 * x) / (p2 + x)), data = dat, start = list(p1 = 0.1845, p2 = 0.0903))
out_nls
```

## Question 3

### a

```{r q3a, echo=FALSE}
########### QUESTION 3 begins here ################### 
mse <- out_nlm$minimum / (length(y_i) - length(theta_nlm))
info_mat <- out_nlm$hessian / 2 / mse
cov_theta <- solve(info_mat)
se <- sqrt(diag(cov_theta))
info_mat
cov_theta
se
```

### b

```{r q3b, echo=FALSE}
vcov(out_nls)
```

Although not exactly the same, the covariance matrices are very similar.

### c

```{r q3c, echo=FALSE}
p1_left <- theta_nlm[1] - 1.96 * se[1]
p1_right <- theta_nlm[1] + 1.96 * se[1]
p2_left <- theta_nlm[2] - 1.96 * se[2]
p2_right <- theta_nlm[2] + 1.96 * se[2]
p1_left
p1_right
p2_left
p2_right
```

```{r q3c confint, echo=FALSE}
confint.default(out_nls)
```

As seen from the above comparison, the "crude" confidence interval is similar to the output by R, but it is wider.

## Question 4

### a

```{r q4a, echo=FALSE}
########### QUESTION 4 begins here ################### 
dat_fit <- function(Z, i, theta0){
  Zboot <- Z[i, ]
  x <- Zboot[[2]]
  y <- Zboot[[1]]
  fn <- function(p){
    yhat <- (p[1] * x) / (p[2] + x)
    sum((y - yhat)^2)
  }
  out <- nlm(fn, p = theta0)
  theta <- out$estimate
}
dat_boot <- boot(dat, dat_fit, R = 20000, theta0 = c(0.1845, 0.0903))
dat_boot
plot(dat_boot, index = 1)
title(main = "Histogram of t0")
plot(dat_boot, index = 2)
title(main = "Histogram of t1")
```

### b

```{r q4b, echo=FALSE}
# gamma 0
boot.ci(dat_boot, conf = 0.95, type = "norm", index = 1)

#gamma 1
boot.ci(dat_boot, conf = 0.95, type = "norm", index = 2)
```

### c

```{r q4c, echo=FALSE}
# gamma 0
boot.ci(dat_boot, conf = 0.95, type = "basic", index = 1)

#gamma 1
boot.ci(dat_boot, conf = 0.95, type = "basic", index = 2)
```

### d

For the most part, the confidence intervals in part b and part c agree. The confidence interval for $\gamma_1$ is much closer since the histogram is pretty much completely normal. This means in part b where we use normal approximation, the confidence intervals will be much closer. For $\gamma_0$, we can see from part a that the histogram is slightly left skewed. Thus, the reflected confidence interval is slightly shifted to the right compared to the "crude" confidence interval. Note that the histogram for $\gamma_0$ is still very close to normal despite skewedness, and thus the confidence intervals do not differ by much.

## Question 5

```{r q5, echo=FALSE}
########### QUESTION 5 begins here ################### 

# Bootstrap
dat_fit2 <- function(Z, i, theta0, x_pred){
  Zboot <- Z[i, ]
  x <- Zboot[[2]]
  y <- Zboot[[1]]
  fn <- function(p){
    yhat <- (p[1] * x) / (p[2] + x)
    sum((y - yhat)^2)
  }
  out <- nlm(fn, p = theta0)
  theta <- out$estimate
  y_pred <- (theta[1] * x_pred) / (theta[2] + x_pred)
}
dat_boot2 <- boot(dat, dat_fit2, R = 20000, theta0 = c(0.1845, 0.0903), x_pred = 27)
Yhat0<-dat_boot2$t0 
Yhatboot<-dat_boot2$t
SEY<-sqrt(var(Yhatboot)+mse)
c(Yhat0-qnorm(.975)*SEY, Yhat0+qnorm(.975)*SEY)

# Predicted
boot.ci(dat_boot2, conf = 0.95,type=c("basic"))
```

As seen above, the prediction interval for "future" Y is wider than the confidence interval. This is because of the added uncertainty from the standard errors of the prediction of the model. A prediction interval is a better representation because it not only takes into account the error of the estimated parameters, but also the error in the model that generates the prediction.

## Question 6

```{r q6, echo=FALSE}
m6 <- lm(y~sqrt(x), data = dat)
n <- nrow(dat)
log_lik_m6 <- logLik(m6)
aic_m6 <- -2 * log_lik_m6 / n + 2 * 2 / n
log_lik_nls <- logLik(out_nls)
aic_nls <- -2 * log_lik_nls / n + 2 * 2 / n
aic_m6
aic_nls
```

The nls model is better since it has a lower AIC.

## Question 7

# Appendix

This section is to be used for including your R code. The following lines of code will take care of it. Please make sure to comment your code appropriately - in particular, demarcating codes belonging to different questions. Among other things, it will be easier for you to debug your own code.

```{r getlabels}
labs = knitr::all_labels()
labs = labs[!labs %in% c("setup","getlabels", "allcode")]
```

```{r allcode,ref.label=labs,eval=FALSE,echo=TRUE}
```